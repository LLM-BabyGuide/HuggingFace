{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.05957256683297341,
  "eval_steps": 500,
  "global_step": 200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 1.620529055595398,
      "learning_rate": 4.985105749180816e-05,
      "loss": 3.2755,
      "step": 10
    },
    {
      "epoch": 0.01,
      "grad_norm": 2.286508321762085,
      "learning_rate": 4.9702114983616324e-05,
      "loss": 3.4343,
      "step": 20
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4563560485839844,
      "learning_rate": 4.9553172475424484e-05,
      "loss": 3.287,
      "step": 30
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.9335110187530518,
      "learning_rate": 4.940422996723265e-05,
      "loss": 3.242,
      "step": 40
    },
    {
      "epoch": 0.01,
      "grad_norm": 3.6002731323242188,
      "learning_rate": 4.925528745904081e-05,
      "loss": 3.2816,
      "step": 50
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.6945163011550903,
      "learning_rate": 4.910634495084897e-05,
      "loss": 3.3183,
      "step": 60
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.4483931064605713,
      "learning_rate": 4.895740244265713e-05,
      "loss": 3.1227,
      "step": 70
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.458514928817749,
      "learning_rate": 4.88084599344653e-05,
      "loss": 3.0974,
      "step": 80
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.1214611530303955,
      "learning_rate": 4.865951742627346e-05,
      "loss": 3.144,
      "step": 90
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.1897960901260376,
      "learning_rate": 4.851057491808162e-05,
      "loss": 3.0431,
      "step": 100
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.7494771480560303,
      "learning_rate": 4.836163240988978e-05,
      "loss": 3.169,
      "step": 110
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.7380197048187256,
      "learning_rate": 4.821268990169795e-05,
      "loss": 3.1142,
      "step": 120
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.2455878257751465,
      "learning_rate": 4.806374739350611e-05,
      "loss": 3.1597,
      "step": 130
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.7956267595291138,
      "learning_rate": 4.791480488531427e-05,
      "loss": 3.2008,
      "step": 140
    },
    {
      "epoch": 0.04,
      "grad_norm": 4.815000534057617,
      "learning_rate": 4.776586237712243e-05,
      "loss": 3.3189,
      "step": 150
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.3080830574035645,
      "learning_rate": 4.761691986893059e-05,
      "loss": 3.0598,
      "step": 160
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.3017590045928955,
      "learning_rate": 4.746797736073876e-05,
      "loss": 3.0998,
      "step": 170
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.9464895725250244,
      "learning_rate": 4.731903485254692e-05,
      "loss": 3.1534,
      "step": 180
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.6066651344299316,
      "learning_rate": 4.717009234435508e-05,
      "loss": 3.1507,
      "step": 190
    },
    {
      "epoch": 0.06,
      "grad_norm": 3.1982953548431396,
      "learning_rate": 4.702114983616324e-05,
      "loss": 2.9769,
      "step": 200
    }
  ],
  "logging_steps": 10,
  "max_steps": 3357,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 20,
  "total_flos": 219345353490432.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
